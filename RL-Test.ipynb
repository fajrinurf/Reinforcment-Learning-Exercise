{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reinforcement Learning: Pengenalan**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di dalam Tutorial ini, akan menjelaskan penggunaan Reinforcement Learning dasar yang akan digunakan, dan juga untuk memenuhi tugas kuliah Advance Machine Learning. Referensi yang akan digunakan di dalam tutorial ini akan berbasis dari buku dan juga paper. untuk kasus yang akan dijelaskan disini adalah penggunaan Reinforcement Learning yang akan menerapkan metode Q-learning tabular klasik untuk [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/) klasik Puzzle. \n",
    "\n",
    "![alt text](https://media2.giphy.com/media/46ib09ZL1SdWuREnj3/giphy.gif?cid=3640f6095c6e92762f3446634d90bc65) ![alt text](https://media0.giphy.com/media/d9QiBcfzg64Io/200w.webp?cid=3640f6095c6e93e92f30655873731752)![alt text](https://i.gifer.com/GpAY.gif)\n",
    "\n",
    "Reinforcement Learning bisa beroperasi dengan melakukan indentifikasi pola yang akan digunakan secara optimal, di dalam konteks dari masalah masalah yang diberikan, sehingga agen pada reinforcement learning dapat membuat keputusan terbaik untuk langkah berikutnya."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q-Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Q-Learning with Frozen Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:  0.8\n",
      "Value iteration policy: [1 3 0 3 0 0 0 0 3 1 1 1 0 2 2 0]\n",
      "\n",
      "\n",
      "policy: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "V: 1\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.         0.        ]]\n",
      "V: 2\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.         0.        ]]\n",
      "\n",
      "policy: [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "\n",
      "V: 3\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.33333333 0.        ]]\n",
      "V: 4\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.17777778 0.46962963]\n",
      " [0.         0.         0.42222222 0.        ]]\n",
      "V: 5\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.04740741 0.        ]\n",
      " [0.         0.         0.23782716 0.52198848]\n",
      " [0.         0.         0.44592593 0.        ]]\n",
      "V: 6\n",
      "[[0.         0.         0.01264198 0.00337119]\n",
      " [0.         0.         0.06679177 0.        ]\n",
      " [0.         0.         0.25811051 0.54135973]\n",
      " [0.         0.         0.45224691 0.        ]]\n",
      "V: 7\n",
      "[[0.         0.         0.02118233 0.00654761]\n",
      " [0.         0.         0.07447809 0.        ]\n",
      " [0.         0.         0.26496177 0.5483524 ]\n",
      " [0.         0.         0.45393251 0.        ]]\n",
      "V: 8\n",
      "[[0.         0.         0.02550945 0.00854855]\n",
      " [0.         0.         0.07745899 0.        ]\n",
      " [0.         0.         0.26727598 0.55083423]\n",
      " [0.         0.         0.454382   0.        ]]\n",
      "V: 9\n",
      "[[0.         0.         0.02745825 0.00960181]\n",
      " [0.         0.         0.07859579 0.        ]\n",
      " [0.         0.         0.26805766 0.55170451]\n",
      " [0.         0.         0.45450187 0.        ]]\n",
      "V: 10\n",
      "[[0.         0.         0.02828108 0.0101021 ]\n",
      " [0.         0.         0.07902366 0.        ]\n",
      " [0.         0.         0.2683217  0.55200699]\n",
      " [0.         0.         0.45453383 0.        ]]\n",
      "\n",
      "policy: [0 1 2 3 0 0 0 0 0 1 2 1 0 1 2 0]\n",
      "\n",
      "V: 11\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.33333333 0.        ]]\n",
      "V: 12\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.17777778 0.46962963]\n",
      " [0.         0.08888889 0.46962963 0.        ]]\n",
      "V: 13\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.04740741 0.        ]\n",
      " [0.         0.07111111 0.26311111 0.52873086]\n",
      " [0.         0.14893827 0.52873086 0.        ]]\n",
      "V: 14\n",
      "[[0.         0.         0.01264198 0.00337119]\n",
      " [0.         0.         0.07353416 0.        ]\n",
      " [0.         0.10987984 0.3015989  0.5547546 ]\n",
      " [0.         0.18071177 0.5547546  0.        ]]\n",
      "V: 15\n",
      "[[0.         0.00337119 0.02387929 0.00816578]\n",
      " [0.         0.         0.08679418 0.        ]\n",
      " [0.         0.12861618 0.31901424 0.56633836]\n",
      " [0.         0.19612437 0.56633836 0.        ]]\n",
      "V: 16\n",
      "[[0.         0.00636781 0.03169047 0.01280587]\n",
      " [0.         0.         0.09352125 0.        ]\n",
      " [0.         0.13737029 0.32698613 0.5715532 ]\n",
      " [0.         0.20332339 0.5715532  0.        ]]\n",
      "V: 17\n",
      "[[0.         0.00845079 0.03680469 0.01664438]\n",
      " [0.         0.         0.09701088 0.        ]\n",
      " [0.         0.14141587 0.33069794 0.57393364]\n",
      " [0.         0.20663376 0.57393364 0.        ]]\n",
      "V: 18\n",
      "[[0.         0.00981458 0.04012266 0.01957638]\n",
      " [0.         0.         0.09888549 0.        ]\n",
      " [0.         0.14328845 0.3324674  0.57504028]\n",
      " [0.         0.2081513  0.57504028 0.        ]]\n",
      "V: 19\n",
      "[[0.         0.01069937 0.04228921 0.02171786]\n",
      " [0.         0.         0.0999351  0.        ]\n",
      " [0.         0.14416499 0.33333751 0.57556741]\n",
      " [0.         0.20885109 0.57556741 0.        ]]\n",
      "V: 20\n",
      "[[0.         0.01127712 0.04371791 0.02324097]\n",
      " [0.         0.         0.10054811 0.        ]\n",
      " [0.         0.14458363 0.33378211 0.57582654]\n",
      " [0.         0.20917827 0.57582654 0.        ]]\n",
      "V: 21\n",
      "[[0.         0.01165811 0.04466853 0.02430679]\n",
      " [0.         0.         0.10092017 0.        ]\n",
      " [0.         0.14478943 0.33401953 0.57595895]\n",
      " [0.         0.20933461 0.57595895 0.        ]]\n",
      "V: 22\n",
      "[[0.         0.01191161 0.04530546 0.02504508]\n",
      " [0.         0.         0.10115333 0.        ]\n",
      " [0.         0.14489444 0.33415233 0.57602968]\n",
      " [0.         0.20941162 0.57602968 0.        ]]\n",
      "\n",
      "policy: [1 2 2 3 0 0 0 0 1 1 1 1 0 2 2 0]\n",
      "\n",
      "V: 23\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.33333333 0.        ]]\n",
      "V: 24\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.17777778 0.46962963]\n",
      " [0.         0.08888889 0.46962963 0.        ]]\n",
      "V: 25\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.04740741 0.        ]\n",
      " [0.         0.07111111 0.2694321  0.53041646]\n",
      " [0.         0.16790123 0.53041646 0.        ]]\n",
      "V: 26\n",
      "[[0.         0.         0.01264198 0.00337119]\n",
      " [0.         0.         0.07521975 0.        ]\n",
      " [0.01896296 0.12167901 0.31533652 0.55886746]\n",
      " [0.         0.21866579 0.55886746 0.        ]]\n",
      "V: 27\n",
      "[[0.         0.00337119 0.02432878 0.00828564]\n",
      " [0.00505679 0.         0.09057741 0.        ]\n",
      " [0.03750453 0.15240182 0.33870313 0.57268549]\n",
      " [0.         0.24798269 0.57268549 0.        ]]\n",
      "V: 28\n",
      "[[0.00224746 0.00738666 0.03285116 0.01317932]\n",
      " [0.01194901 0.         0.09908114 0.        ]\n",
      " [0.05064169 0.169954   0.35075333 0.57958369]\n",
      " [0.         0.26416591 0.57958369 0.        ]]\n",
      "V: 29\n",
      "[[0.0057555  0.01073008 0.03869643 0.01734802]\n",
      " [0.01822565 0.         0.10385327 0.        ]\n",
      " [0.05882552 0.17966527 0.35702204 0.58309486]\n",
      " [0.         0.27291063 0.58309486 0.        ]]\n",
      "V: 30\n",
      "[[0.00925633 0.0131804  0.04263939 0.02062278]\n",
      " [0.02301533 0.         0.10657638 0.        ]\n",
      " [0.06359754 0.18494139 0.36030163 0.58490573]\n",
      " [0.         0.27758584 0.58490573 0.        ]]\n",
      "V: 31\n",
      "[[0.01212055 0.01488528 0.04529028 0.02307622]\n",
      " [0.02632891 0.         0.10815784 0.        ]\n",
      " [0.06627705 0.1877772  0.36202364 0.58584783]\n",
      " [0.         0.28007167 0.58584783 0.        ]]\n",
      "V: 32\n",
      "[[0.0142226  0.01604682 0.04707316 0.02486016]\n",
      " [0.02848762 0.         0.10909248 0.        ]\n",
      " [0.0677478  0.1892915  0.36292991 0.58634073]\n",
      " [0.         0.2813896  0.58634073 0.        ]]\n",
      "V: 33\n",
      "[[0.01566854 0.01683199 0.04827355 0.0261317 ]\n",
      " [0.02984106 0.         0.10965426 0.        ]\n",
      " [0.06854381 0.19009689 0.36340756 0.58659954]\n",
      " [0.         0.28208726 0.58659954 0.        ]]\n",
      "V: 34\n",
      "[[0.01662442 0.01736148 0.04908253 0.02702558]\n",
      " [0.03066914 0.         0.10999736 0.        ]\n",
      " [0.06897085 0.19052418 0.36365954 0.58673576]\n",
      " [0.         0.28245626 0.58673576 0.        ]]\n",
      "\n",
      "policy: [1 3 2 3 0 0 0 0 3 1 1 1 0 2 2 0]\n",
      "\n",
      "V: 35\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.33333333 0.        ]]\n",
      "V: 36\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.17777778 0.46962963]\n",
      " [0.         0.08888889 0.46962963 0.        ]]\n",
      "V: 37\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.04740741 0.        ]\n",
      " [0.         0.07111111 0.2694321  0.53041646]\n",
      " [0.         0.16790123 0.53041646 0.        ]]\n",
      "V: 38\n",
      "[[0.         0.         0.01264198 0.00337119]\n",
      " [0.         0.         0.07521975 0.        ]\n",
      " [0.01896296 0.12167901 0.31533652 0.55886746]\n",
      " [0.         0.21866579 0.55886746 0.        ]]\n",
      "V: 39\n",
      "[[0.         0.00337119 0.02432878 0.00828564]\n",
      " [0.00505679 0.         0.09057741 0.        ]\n",
      " [0.038853   0.15276142 0.33879902 0.57271106]\n",
      " [0.         0.24807858 0.57271106 0.        ]]\n",
      "V: 40\n",
      "[[0.00224746 0.00798598 0.03285116 0.01317932]\n",
      " [0.0123086  0.         0.09910671 0.        ]\n",
      " [0.05437947 0.17100189 0.3510464  0.57966866]\n",
      " [0.         0.26447774 0.57966866 0.        ]]\n",
      "V: 41\n",
      "[[0.00601121 0.01249289 0.03870325 0.01734984]\n",
      " [0.01938648 0.         0.10393324 0.        ]\n",
      " [0.06527142 0.18154548 0.35756875 0.58326331]\n",
      " [0.         0.27351784 0.58326331 0.        ]]\n",
      "V: 42\n",
      "[[0.01010416 0.01634675 0.04266302 0.02063005]\n",
      " [0.02526988 0.         0.10672847 0.        ]\n",
      " [0.07255648 0.18763815 0.3611106  0.58516638]\n",
      " [0.         0.27851181 0.58516638 0.        ]]\n",
      "V: 43\n",
      "[[0.01379221 0.01941386 0.04533908 0.02309312]\n",
      " [0.02976495 0.         0.10838658 0.        ]\n",
      " [0.07732255 0.19118532 0.36307149 0.58619676]\n",
      " [0.         0.28129694 0.58619676 0.        ]]\n",
      "V: 44\n",
      "[[0.01679227 0.02174539 0.04715167 0.02489011]\n",
      " [0.03303461 0.         0.10939284 0.        ]\n",
      " [0.08041133 0.1932746  0.36417817 0.58676665]\n",
      " [0.         0.28287155 0.58676665 0.        ]]\n",
      "V: 45\n",
      "[[0.01908594 0.02346213 0.04838257 0.02617674]\n",
      " [0.03534183 0.         0.1100162  0.        ]\n",
      " [0.0824074  0.1945219  0.36481472 0.58708836]\n",
      " [0.         0.28377602 0.58708836 0.        ]]\n",
      "V: 46\n",
      "[[0.02077064 0.02469742 0.04922013 0.0270863 ]\n",
      " [0.03693863 0.         0.11040929 0.        ]\n",
      " [0.08369812 0.19527703 0.36518767 0.58727361]\n",
      " [0.         0.28430438 0.58727361 0.        ]]\n",
      "V: 47\n",
      "[[0.02197512 0.02557138 0.04979086 0.02772359]\n",
      " [0.03802983 0.         0.11066094 0.        ]\n",
      " [0.08453466 0.19574046 0.36541005 0.58738231]\n",
      " [0.         0.28461825 0.58738231 0.        ]]\n",
      "V: 48\n",
      "[[0.02282036 0.02618203 0.0501801  0.02816727]\n",
      " [0.03876929 0.         0.11082404 0.        ]\n",
      " [0.08507851 0.19602848 0.36554483 0.58744724]\n",
      " [0.         0.28480774 0.58744724 0.        ]]\n",
      "\n",
      "Policy iteration policy: [1 3 2 3 0 0 0 0 3 1 1 1 0 2 2 0]\n",
      "\n",
      "------------------------\n",
      "END\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# You need this part\n",
    "# S:Start, F:Frozen, H:Hole, G:Goal\n",
    "map = [\"SFFF\", \"FHFH\", \"FFFF\", \"HFFG\"]\n",
    "# is_slippery=True means stochastic and is_slippery=False means deterministic\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"human\", desc=map, map_name=\"4x4\", is_slippery=True)\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "# You need to find the policy using both value iteration and policy iteration\n",
    "# You may not need this part!\n",
    "action = [\"left\", \"down\", \"right\", \"up\"]\n",
    "ncols = 4\n",
    "nrows = 4\n",
    "e = 0.001\n",
    "max_iterations = 1000 #  maximum iterations if there is an infinite loop\n",
    "\n",
    "# GIVEN\n",
    "# A sample policy to make the following while loop works\n",
    "# policy = [1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 2, 0]\n",
    "\n",
    "#  Initializing the variables\n",
    "n_states = env.observation_space.n # the total number of states in the environment\n",
    "n_actions = env.action_space.n # number of possible actions in the environment\n",
    "gamma_list = [0.8] # substitute with ('0.5' and '1')\n",
    "\n",
    "'''\n",
    "This function implements the value iteration algorithm to compute the optimal policy.\n",
    "\n",
    "It initializes the state value function (V) for all states to 0 and then iteratively updates the values until they converge to the optimal values.\n",
    "The loop continues until the maximum change in any value is less than the error threshold (e).\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "env : an object of a Gym environment class\n",
    "    Given environment\n",
    "\n",
    "gamma : float\n",
    "    Discount factor\n",
    "\n",
    "e : float\n",
    "    Error threshold\n",
    "\n",
    "Returns\n",
    "-------\n",
    "policy\n",
    "    1-D NumPy array of integers\n",
    "    Each element in the array represents the best action to take in the corresponding state to maximize the expected cumulative reward\n",
    "    The optimal policy\n",
    "\n",
    "'''\n",
    "def value_iteration(env, gamma, e):\n",
    "    V = np.zeros(n_states)\n",
    "\n",
    "    # check for convergence\n",
    "    # runs until 'delta' is less than a predefined value 'e'\n",
    "    while True:\n",
    "        delta = 0   # the maximum absolute difference between the old value of a state v and the new value V[s] computed in the current iteration\n",
    "        for s in range(n_states):\n",
    "            v = V[s]\n",
    "            q_vals = np.zeros(n_actions)\n",
    "            for a in range(n_actions):\n",
    "                for p, s_next, r, done in env.P[s][a]:\n",
    "                    q_vals[a] += p * (r + gamma * V[s_next])\n",
    "                V[s] = max(q_vals)\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        if delta < e:\n",
    "            break\n",
    "    policy = np.zeros(n_states, dtype=int)\n",
    "    for s in range(n_states):\n",
    "        q_vals = np.zeros(n_actions)\n",
    "        for a in range(n_actions):\n",
    "            for p, s_next, r, done in env.P[s][a]:\n",
    "                q_vals[a] += p * (r + gamma * V[s_next])              \n",
    "            policy[s] = np.argmax(q_vals)\n",
    "    return policy\n",
    "\n",
    "'''\n",
    "This function implements the policy iteration algorithm to compute the optimal policy.\n",
    "\n",
    "It initializes a random policy for all states, then iteratively evaluates and improves the policy until convergence.\n",
    "In the evaluation step, it computes the state values for the given policy until they converge to the optimal values.\n",
    "In the improvement step, it updates the policy for each state by selecting the action that maximizes the expected value of the next state.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "env : an object of a Gym environment class\n",
    "    Given environment\n",
    "\n",
    "gamma : float\n",
    "    Discount factor\n",
    "\n",
    "e : float\n",
    "    Error threshold\n",
    "\n",
    "Returns\n",
    "-------\n",
    "policy\n",
    "    1-D NumPy array of integers\n",
    "    Each element in the array represents the best action to take in the corresponding state to maximize the expected cumulative reward.\n",
    "    The optimal policy.\n",
    "\n",
    "'''\n",
    "def policy_iteration(env, gamma, e):\n",
    "    num = 0 # to check for the iterations\n",
    "    policy = np.zeros(n_states, dtype=int)\n",
    "    print()\n",
    "    print(\"policy:\", policy) # Add print statement to see policy at each step\n",
    "    print() \n",
    "    while True:\n",
    "        V = np.zeros(n_states)\n",
    "        while True:\n",
    "            delta = 0\n",
    "            #if num > max_iterations:   # stops iteration at 1000 but the GUI hangs\n",
    "            #    break                \n",
    "            for s in range(n_states):\n",
    "                v = V[s]\n",
    "                a = policy[s]\n",
    "                q_val = 0\n",
    "                for p, s_next, r, done in env.P[s][a]:\n",
    "                    q_val += p * (r + gamma * V[s_next])\n",
    "                V[s] = q_val\n",
    "                delta = max(delta, abs(v - V[s]))\n",
    "            num += 1 # increment to keep count\n",
    "            print(\"V: \" + str(num))\n",
    "            print(V.reshape(4, 4)) # Add print statement to see V values at each step\n",
    "            if delta < e:\n",
    "                break\n",
    "        policy_stable = True\n",
    "\n",
    "        # check for convergence\n",
    "        # old policy at each state is saved in 'old_action', and then the Q-values for each action at the state are evaluated using the updated \n",
    "        # value function 'V'. The policy is then updated to choose the action with the highest Q-value, and if the updated policy at any state \n",
    "        # is different from the old policy, then policy_stable is set to False.\n",
    "        for s in range(n_states):\n",
    "            old_action = policy[s]\n",
    "            q_vals = np.zeros(n_actions)\n",
    "            for a in range(n_actions):\n",
    "                for p, s_next, r, done in env.P[s][a]:\n",
    "                    q_vals[a] += p * (r + gamma * V[s_next])\n",
    "            policy[s] = np.argmax(q_vals)\n",
    "            if old_action != policy[s]:\n",
    "                policy_stable = False\n",
    "        if policy_stable: # if 'policy_stable' remains True after the loop, then the policy is considered to have converged and the iteration loop is broken\n",
    "            break\n",
    "        print()\n",
    "        print(\"policy:\", policy) # Add print statement to see policy at each step\n",
    "        print()  \n",
    "    return policy\n",
    "\n",
    "# Loop to print out the optimal policies:\n",
    "# Both policies are represented as arrays of integers, with each index corresponding to a state in the environment and the value at that \n",
    "# index representing the action to be taken in that state according to the optimal policy\n",
    "for gamma in gamma_list:\n",
    "    print(\"gamma: \", gamma)\n",
    "    value_policy = value_iteration(env, gamma, e) #the optimal policy obtained by running the value iteration algorithm on the environment\n",
    "    print(\"Value iteration policy:\", value_policy)\n",
    "    print()\n",
    "    policy_policy = policy_iteration(env, gamma, e) #the optimal policy obtained by running the policy iteration algorithm on the environmeny\n",
    "    print() \n",
    "    print(\"Policy iteration policy:\", policy_policy)\n",
    "    print()\n",
    "    print(\"------------------------\")\n",
    "\n",
    "\n",
    "# GIVEN\n",
    "# This part uses the found policy to interact with the environment.\n",
    "# You don't need to change anything here.\n",
    "\n",
    "s = 0\n",
    "goal = ncols * nrows - 1\n",
    "while s != goal:\n",
    "    a = value_policy[s]\n",
    "    s, r, t, f, p = env.step(a)\n",
    "    if t == True and s != goal:\n",
    "        env.reset()\n",
    "        s = 0\n",
    "print(\"END\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake\n",
    "import gym.wrappers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 100\n",
    "PERCENTILE = 30\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### wrapper for discrete sample space\n",
    "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
    "  def __init__(self,env):\n",
    "    super(DiscreteOneHotWrapper,self).__init__(env)\n",
    "    assert isinstance(env.observation_space,gym.spaces.Discrete)\n",
    "    self.observation_space = gym.spaces.Box(0.0,1.0,(env.observation_space.n,),dtype=np.float32)\n",
    "  \n",
    "  #overriden\n",
    "  def observation(self,observation):\n",
    "    result = np.copy(self.observation_space.low)\n",
    "    result[observation] = 1.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### simple neural network\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,obs_size,hidden_size,action_size):\n",
    "    super(Net,self).__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        nn.Linear(obs_size,hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size,action_size)\n",
    "    )\n",
    "  ## overriden\n",
    "  def forward(self,x):\n",
    "    return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classes for tupple\n",
    "Episode = namedtuple(\"Episode\",[\"reward\",\"step\"])\n",
    "Episode_step = namedtuple(\"EpisodeStep\",[\"action\",\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training on network + random_walk for the data\n",
    "def iteration_batch(net,env,batch_size):\n",
    "  episode_reward = 0.0\n",
    "  batch = []\n",
    "  episode_step = []\n",
    "  obs = env.reset()\n",
    "  softmax = nn.Softmax(dim=1)\n",
    "  # 3 elements for making a dataset for RL\n",
    "  while True:\n",
    "    obs_vector = torch.FloatTensor([obs])\n",
    "    action_score = net(obs_vector)\n",
    "    action_probability_vector = softmax(action_score)\n",
    "    action_probability = action_probability_vector.data.numpy()[0]\n",
    "    action = np.random.choice(len(action_probability),p=action_probability)\n",
    "    next_obs, reward, is_done, _ = env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_step.append(Episode_step(action=action,observation=obs))\n",
    "    if is_done:\n",
    "      batch.append(Episode(reward=reward,step=episode_step))\n",
    "      episode_reward = 0.0\n",
    "      episode_step = []\n",
    "      next_obs = env.reset() #important\n",
    "      if len(batch) == batch_size:\n",
    "        yield batch\n",
    "        batch = []\n",
    "      \n",
    "    obs = next_obs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter for elite batch\n",
    "def filter_batch(batch,percentile):\n",
    "  \n",
    "  reward = list(map(lambda sample: sample.reward * (GAMMA**len(sample.step)),batch))\n",
    "\n",
    "  reward_bound = np.percentile(reward,percentile)\n",
    "\n",
    "  train_obs = []\n",
    "  train_action = []\n",
    "  train_elite = []\n",
    "\n",
    "  for example,discount_reward in zip(batch,reward):\n",
    "\n",
    "    if discount_reward > reward_bound:\n",
    "      train_obs.extend(list(map(lambda step : step.observation,example.step)))\n",
    "      train_action.extend(list(map(lambda step : step.action,example.step)))\n",
    "      train_elite.append(example)\n",
    "\n",
    "  return train_elite,train_obs,train_action,reward_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fajri\\AppData\\Local\\Temp\\ipykernel_7616\\1453775031.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  obs_vector = torch.FloatTensor([obs])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 16 at dim 2 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m softmax \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(comment\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-frozenlake-nonslippery\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m iter_no , batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iteration_batch(net,env,BATCH_SIZE)):\n\u001b[0;32m     13\u001b[0m   reward_mean \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(np\u001b[39m.\u001b[39mmean(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m step : step\u001b[39m.\u001b[39mreward,batch))))\n\u001b[0;32m     14\u001b[0m   full_batch,train_obs,train_action,reward_bound \u001b[39m=\u001b[39m filter_batch(full_batch\u001b[39m+\u001b[39mbatch,PERCENTILE)\n",
      "Cell \u001b[1;32mIn[60], line 10\u001b[0m, in \u001b[0;36miteration_batch\u001b[1;34m(net, env, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# 3 elements for making a dataset for RL\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m   obs_vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mFloatTensor([obs])\n\u001b[0;32m     11\u001b[0m   action_score \u001b[39m=\u001b[39m net(obs_vector)\n\u001b[0;32m     12\u001b[0m   action_probability_vector \u001b[39m=\u001b[39m softmax(action_score)\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 16 at dim 2 (got 1)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## training pharse\n",
    "full_batch = []\n",
    "env = gym.envs.toy_text.frozen_lake.FrozenLakeEnv(is_slippery=False)\n",
    "env = gym.wrappers.TimeLimit(env,max_episode_steps=100)\n",
    "env = DiscreteOneHotWrapper(env)\n",
    "net = Net(env.observation_space.shape[0],HIDDEN_SIZE,env.action_space.n)\n",
    "optimizer = optim.Adam(params=net.parameters(),lr=0.01)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-nonslippery\")\n",
    "\n",
    "for iter_no , batch in enumerate(iteration_batch(net,env,BATCH_SIZE)):\n",
    "  reward_mean = float(np.mean(list(map(lambda step : step.reward,batch))))\n",
    "  full_batch,train_obs,train_action,reward_bound = filter_batch(full_batch+batch,PERCENTILE)\n",
    "  if not full_batch:\n",
    "    continue\n",
    "  obs_vector = torch.FloatTensor(train_obs)\n",
    "  action_vector = torch.LongTensor(train_action)\n",
    "  full_batch = full_batch[-500:]\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  action_probability = net(obs_vector)\n",
    "  \n",
    "  loss_vector = objective(action_probability,action_vector)\n",
    "  loss_vector.backward()\n",
    "  optimizer.step()\n",
    "  print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (\n",
    "          iter_no, loss_vector.item(), reward_mean, reward_bound))\n",
    "  \n",
    "  writer.add_scalar(\"loss\", loss_vector.item(), iter_no)\n",
    "  writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "  writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "  if reward_mean > 0.89:\n",
    "      print(\"Solved!\")\n",
    "      break\n",
    "  writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sarsa...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 187\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m Q\n\u001b[0;32m    186\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRunning sarsa...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m Q \u001b[39m=\u001b[39m sarsa(env)\n\u001b[0;32m    188\u001b[0m plot_V(Q, env)\n\u001b[0;32m    189\u001b[0m plot_Q(Q, env)\n",
      "Cell \u001b[1;32mIn[42], line 136\u001b[0m, in \u001b[0;36msarsa\u001b[1;34m(env, alpha, gamma, epsilon, num_ep)\u001b[0m\n\u001b[0;32m    134\u001b[0m     a \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mn))\n\u001b[0;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(Q[s])\n\u001b[0;32m    137\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m    138\u001b[0m     eps_length \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def print_policy(Q, env):\n",
    "    \"\"\" This is a helper function to print a nice policy from the Q function\"\"\"\n",
    "    moves = [u\"←\", u\"↓\", u\"→\", u\"↑\"]\n",
    "    if not hasattr(env, \"desc\"):\n",
    "        env = env.env\n",
    "    dims = env.desc.shape\n",
    "    policy = np.chararray(dims, unicode=True)\n",
    "    policy[:] = \" \"\n",
    "    for s in range(len(Q)):\n",
    "        idx = np.unravel_index(s, dims)\n",
    "        policy[idx] = moves[np.argmax(Q[s])]\n",
    "        if env.desc[idx] in [\"H\", \"G\"]:\n",
    "            policy[idx] = u\"·\"\n",
    "    print(\n",
    "        \"\\n\".join([\"\".join([u\"{:2}\".format(item) for item in row]) for row in policy])\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_V(Q, env):\n",
    "    \"\"\" This is a helper function to plot the state values from the Q function\"\"\"\n",
    "    fig = plt.figure()\n",
    "    if not hasattr(env, \"desc\"):\n",
    "        env = env.env\n",
    "    dims = env.desc.shape\n",
    "    V = np.zeros(dims)\n",
    "    for s in range(len(Q)):\n",
    "        idx = np.unravel_index(s, dims)\n",
    "        V[idx] = np.max(Q[s])\n",
    "        if env.desc[idx] in [\"H\", \"G\"]:\n",
    "            V[idx] = 0.0\n",
    "    plt.imshow(\n",
    "        V,\n",
    "        origin=\"upper\",\n",
    "        extent=[0, dims[0], 0, dims[1]],\n",
    "        vmin=0.0,\n",
    "        vmax=0.6,\n",
    "        cmap=plt.cm.RdYlGn,\n",
    "        interpolation=\"none\",\n",
    "    )\n",
    "    for x, y in product(range(dims[0]), range(dims[1])):\n",
    "        plt.text(\n",
    "            y + 0.5,\n",
    "            dims[0] - x - 0.5,\n",
    "            \"{:.3f}\".format(V[x, y]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "        )\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "def plot_Q(Q, env):\n",
    "    \"\"\" This is a helper function to plot the Q function \"\"\"\n",
    "    from matplotlib import colors, patches\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "\n",
    "    if not hasattr(env, \"desc\"):\n",
    "        env = env.env\n",
    "    dims = env.desc.shape\n",
    "\n",
    "    up = np.array([[0, 1], [0.5, 0.5], [1, 1]])\n",
    "    down = np.array([[0, 0], [0.5, 0.5], [1, 0]])\n",
    "    left = np.array([[0, 0], [0.5, 0.5], [0, 1]])\n",
    "    right = np.array([[1, 0], [0.5, 0.5], [1, 1]])\n",
    "    tri = [left, down, right, up]\n",
    "    pos = [[0.2, 0.5], [0.5, 0.2], [0.8, 0.5], [0.5, 0.8]]\n",
    "\n",
    "    cmap = plt.cm.RdYlGn\n",
    "    norm = colors.Normalize(vmin=0.0, vmax=0.6)\n",
    "\n",
    "    ax.imshow(\n",
    "        np.zeros(dims),\n",
    "        origin=\"upper\",\n",
    "        extent=[0, dims[0], 0, dims[1]],\n",
    "        vmin=0.0,\n",
    "        vmax=0.6,\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    ax.grid(which=\"major\", color=\"black\", linestyle=\"-\", linewidth=2)\n",
    "\n",
    "    for s in range(len(Q)):\n",
    "        idx = np.unravel_index(s, dims)\n",
    "        x, y = idx\n",
    "        if env.desc[idx] in [\"H\", \"G\"]:\n",
    "            ax.add_patch(patches.Rectangle((y, 3 - x), 1, 1, color=cmap(0.0)))\n",
    "            plt.text(\n",
    "                y + 0.5,\n",
    "                dims[0] - x - 0.5,\n",
    "                \"{:.2f}\".format(0.0),\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "            )\n",
    "            continue\n",
    "        for a in range(len(tri)):\n",
    "            ax.add_patch(\n",
    "                patches.Polygon(tri[a] + np.array([y, 3 - x]), color=cmap(Q[s][a]))\n",
    "            )\n",
    "            plt.text(\n",
    "                y + pos[a][0],\n",
    "                dims[0] - 1 - x + pos[a][1],\n",
    "                \"{:.2f}\".format(Q[s][a]),\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                fontsize=9,\n",
    "                fontweight=(\"bold\" if Q[s][a] == np.max(Q[s]) else \"normal\"),\n",
    "            )\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "def sarsa(env, alpha=0.1, gamma=0.9, epsilon=0.1, num_ep=int(1e4)):\n",
    "    # Q = np.zeros((env.observation_space.n,  env.action_space.n))\n",
    "    Q = np.random.rand(env.observation_space.n, env.action_space.n)                     # initialize Q with random values\n",
    "    Q[env.observation_space.n - 1, :] = 0                                               # set Q(terminal state, .) to 0\n",
    "    eps_lengths = np.zeros(int(num_ep / 100))\n",
    "    eps_length = 0\n",
    "\n",
    "    # TODO: implement the sarsa algorithm\n",
    "    # This is some starting point performing random walks in the environment:\n",
    "    for i in range(num_ep):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        if random.random() < epsilon:                                                   # choose action by epsilon greedy policy\n",
    "            a = random.choice(range(env.action_space.n))\n",
    "        else:\n",
    "            a = np.argmax(Q[s])\n",
    "        while not done:\n",
    "            eps_length += 1\n",
    "            s_, r, done, _ = env.step(a)\n",
    "            if random.random() < epsilon:\n",
    "                a_ = random.choice(range(env.action_space.n))                           # choose random action\n",
    "            else:\n",
    "                a_ = np.argmax(Q[s_])                                                   # choose greedy action\n",
    "            Q[s][a] = Q[s][a] + alpha * (r + gamma * Q[s_, a_] - Q[s, a])               # update action-value\n",
    "            s = s_\n",
    "            a = a_\n",
    "        if i % 100 == 0:\n",
    "            eps_lengths[int(i / 100)] = eps_length / 100                                # store average episode length over 100 episodes\n",
    "            eps_length = 0\n",
    "    plt.plot(range(num_ep)[0::100], eps_lengths)\n",
    "    plt.xlabel(\"Episode Number\")\n",
    "    plt.ylabel(\"Length of episode\")\n",
    "    return Q\n",
    "\n",
    "\n",
    "def qlearning(env, alpha=0.1, gamma=0.9, epsilon=0.1, num_ep=int(1e4)):\n",
    "    # Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    Q = np.random.rand(env.observation_space.n, env.action_space.n)                     # initialize Q with random values\n",
    "    Q[env.observation_space.n - 1, :] = 0\n",
    "    eps_lengths = np.zeros(int(num_ep / 100))\n",
    "    eps_length = 0\n",
    "\n",
    "    # TODO: implement the qlearning algorithm\n",
    "    for i in range(num_ep):\n",
    "        eps_length = 0\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            eps_length += 1\n",
    "            if random.random() < epsilon:                                               # choose action using epsilon-greedy policy\n",
    "                a = random.choice(range(env.action_space.n))\n",
    "            else:\n",
    "                a = np.argmax(Q[s])\n",
    "            s_, r, done, _ = env.step(a)\n",
    "            Q[s][a] = Q[s][a] + alpha * (r + gamma * np.amax(Q[s_]) - Q[s][a])          # update Q value using Q-learning algorithm\n",
    "            s = s_\n",
    "        if i % 100 == 0:\n",
    "            eps_lengths[int(i / 100)] = eps_length / 100\n",
    "            eps_length = 0\n",
    "    plt.plot(range(num_ep)[0::100], eps_lengths)\n",
    "    plt.xlabel(\"Episode Number\")\n",
    "    plt.ylabel(\"Length of episode\")\n",
    "    return Q\n",
    "\n",
    "\n",
    "print(\"Running sarsa...\")\n",
    "Q = sarsa(env)\n",
    "plot_V(Q, env)\n",
    "plot_Q(Q, env)\n",
    "print_policy(Q, env)\n",
    "plt.show()\n",
    "\n",
    "print(\"Running qlearning\")\n",
    "Q = qlearning(env)\n",
    "plot_V(Q, env)\n",
    "plot_Q(Q, env)\n",
    "print_policy(Q, env)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BruteForce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States:  9\n",
      "Actions:  4\n",
      "current environment: \n"
     ]
    },
    {
     "ename": "ResetNeeded",
     "evalue": "Cannot call `env.render()` before calling `env.reset()`, if this is a intended action, set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResetNeeded\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 158\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# $ optimalpolicies = policy_right\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[39m# This code can be used to \"rollout\" a policy in the environment:\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[39m#         print(\"Finished episode\")\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[39m#         break\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[43], line 128\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m    126\u001b[0m     \u001b[39m# print the environment\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcurrent environment: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m     env\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    129\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    131\u001b[0m     \u001b[39m# Here a policy is just an array with the action for a state as element\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Fajri\\Anaconda\\envs\\gpu2\\lib\\site-packages\\gym\\core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[0;32m    328\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Fajri\\Anaconda\\envs\\gpu2\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:47\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Renders the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m---> 47\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[0;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m     )\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mResetNeeded\u001b[0m: Cannot call `env.render()` before calling `env.reset()`, if this is a intended action, set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Init environment\n",
    "# Lets use a smaller 3x3 custom map for faster computations\n",
    "custom_map3x3 = [\n",
    "    'SFF',\n",
    "    'FFF',\n",
    "    'FHG',\n",
    "]\n",
    "env = gym.make(\"FrozenLake-v1\", desc=custom_map3x3)\n",
    "# TODO: Uncomment the following line to try the default map (4x4):\n",
    "#env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "# Uncomment the following lines for even larger maps:\n",
    "# random_map = generate_random_map(size=5, p=0.8)\n",
    "# env = gym.make(\"FrozenLake-v0\", desc=random_map)\n",
    "\n",
    "# Init some useful variables:\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"States: \", n_states)\n",
    "print(\"Actions: \", n_actions)\n",
    "# the r vector is zero everywhere except for the goal state (last state)\n",
    "r = np.zeros(n_states)\n",
    "r[-1] = 1.\n",
    "\n",
    "gamma = 0.8\n",
    "\n",
    "\n",
    "# left = 0; right =2 ; up=1; down=4\n",
    "steps = [[]]\n",
    "\n",
    "''' Helper function to generate list of all possible moves (modulo 4 counter) '''\n",
    "\n",
    "\n",
    "def moduloCount(n, base):\n",
    "\n",
    "    digits = \"0123\"  # 4 possible moves\n",
    "\n",
    "    if n < base:\n",
    "        x = digits[n]\n",
    "    else:\n",
    "        x = moduloCount(n//base, base) + digits[n % base]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\" This is a helper function that returns the transition probability matrix P for a policy \"\"\"\n",
    "\n",
    "\n",
    "def trans_matrix_for_policy(policy):\n",
    "    transitions = np.zeros((n_states, n_states))\n",
    "    for s in range(n_states):\n",
    "        probs = env.P[s][policy[s]]\n",
    "        for el in probs:\n",
    "            transitions[s, el[1]] += el[0]\n",
    "    return transitions\n",
    "\n",
    "\n",
    "\"\"\" This is a helper function that returns terminal states \"\"\"\n",
    "\n",
    "\n",
    "def terminals():\n",
    "    terms = []\n",
    "    for s in range(n_states):\n",
    "        # terminal is when we end with probability 1 in terminal:\n",
    "        if env.P[s][0][0][0] == 1.0 and env.P[s][0][0][3] == True:\n",
    "            terms.append(s)\n",
    "    return terms\n",
    "\n",
    "\n",
    "def value_policy(policy):\n",
    "    P = trans_matrix_for_policy(policy)\n",
    "    # TODO: calculate and return v\n",
    "    # (P, r and gamma already given)\n",
    "    I = np.eye(n_states)\n",
    "    v = np.matmul(np.linalg.inv(I - gamma*P), r)\n",
    "    return v\n",
    "\n",
    "\n",
    "def bruteforce_policies():\n",
    "    #terms = terminals()\n",
    "    optimalpolicies = []\n",
    "    policy = np.zeros(n_states, dtype=np.int)\n",
    "    optimalvalue = np.zeros(n_states)\n",
    "    policyList = []\n",
    "    valueList = []  # Store values of all policies\n",
    "    # Total combinations of states = 4^10 (n_actions ^ n_states)\n",
    "    for i in range(n_actions ** n_states):\n",
    "        if(i % 1000 == 0):\n",
    "            print(\"State_idx: \", i)\n",
    "\n",
    "        x = moduloCount(i, n_actions)\n",
    "        L = len(x)\n",
    "        policy = list('0'*(n_states-L)+x)\n",
    "        policy = [int(i) for i in policy]\n",
    "        policyList.append(policy)\n",
    "        valueList.append(value_policy(policy))\n",
    "\n",
    "    optimalvalue = np.amax(valueList, axis=0)\n",
    "    equalityMatrix = (valueList == optimalvalue)\n",
    "    idx = 0\n",
    "    for row in equalityMatrix:\n",
    "        if(all(row)):  # Check if values of all states are maximum\n",
    "            optimalpolicies.append(policyList[idx])\n",
    "        idx += 1\n",
    "\n",
    "    #print(str(i)+\"---  \"+policy)\n",
    "    # in the discrete case a policy is just an array with action = policy[state]\n",
    "\n",
    "    # TODO: implement code that tries all possible policies, calculate the values using def value_policy.\n",
    "    # Find the optimal values and the optimal policies to answer the exercise questions.\n",
    "\n",
    "    print(\"Optimal value function:\")\n",
    "    print(optimalvalue)\n",
    "    print(\"number optimal policies:\")\n",
    "    print(len(optimalpolicies))\n",
    "    print(\"optimal policies:\")\n",
    "    print(np.array(optimalpolicies))\n",
    "    return optimalpolicies\n",
    "\n",
    "\n",
    "def main():\n",
    "    # print the environment\n",
    "    print(\"current environment: \")\n",
    "    env.render()\n",
    "    print(\"\")\n",
    "\n",
    "    # Here a policy is just an array with the action for a state as element\n",
    "    policy_left = np.zeros(n_states, dtype=np.int)  # 0 for all states\n",
    "    policy_right = np.ones(n_states, dtype=np.int) * 2  # 2 for all states\n",
    "\n",
    "    # Value functions:\n",
    "    # print(\"Value function for policy_left (always going left):\")\n",
    "    # print(value_policy(policy_left))\n",
    "    # print(\"Value function for policy_right (always going right):\")\n",
    "    # print(value_policy(policy_right))\n",
    "\n",
    "    optimalpolicies = bruteforce_policies()\n",
    "    # $ optimalpolicies = policy_right\n",
    "    # This code can be used to \"rollout\" a policy in the environment:\n",
    "\n",
    "    # print(\"rollout policy:\")\n",
    "    # maxiter = 100\n",
    "    # state = env.reset()\n",
    "    # for i in range(maxiter):\n",
    "    #     new_state, reward, done, info = env.step(optimalpolicies[0][state])\n",
    "    #     env.render()\n",
    "    #     state = new_state\n",
    "    #     if done:\n",
    "    #         print(\"Finished episode\")\n",
    "    #         break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N_Step Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nstep_sarsa(env, n=1, alpha=0.1, gamma=0.9, epsilon=0.1, num_ep=int(1e4)):\n",
    "\n",
    "    \"\"\" TODO: implement the n-step sarsa algorithm \"\"\"\n",
    "    \n",
    "    total_episode_length = 0\n",
    "    for ep in tqdm(range(num_ep)):      \n",
    "      state = env.reset()\n",
    "      obs = env.reset()\n",
    "      n_states = env.observation_space.n\n",
    "      n_actions = env.action_space.n\n",
    "      Q = np.random.rand(n_states,n_actions)   # Initializing random Q values for each (s,a)\n",
    "      Q[-1,:] = 0                              # Setting final state values to 0\n",
    "      policy = np.argmax(Q,axis=1)             # Greedy policy based on the random Q(s,a)     \n",
    "\n",
    "      done = False\n",
    "      t = 0\n",
    "      tau = 0\n",
    "      G=0\n",
    "      T = np.inf\n",
    "\n",
    "      states = [0]\n",
    "      actions = [policy[0]]\n",
    "      rewards = [0]\n",
    "      \n",
    "      while not done:\n",
    "        if t < T:\n",
    "          A = actions[t]   # take action A_t\n",
    "          S , R , done , _ =  env.step(A)\n",
    "          states.append(S)\n",
    "          actions.append(A)\n",
    "          rewards.append(R)\n",
    "\n",
    "          if done:\n",
    "            T = t+1\n",
    "          else:\n",
    "            actions.append(policy[S])  # action corresponding to current state S\n",
    "\n",
    "        tau = t - n + 1\n",
    "        if tau >= 0:\n",
    "          for i in range(tau+1,min((tau+n,T))):\n",
    "            R_i = rewards[i]\n",
    "            G += ((gamma ** (i-tau-1)) * R_i)\n",
    "          \n",
    "          if (tau+n) < T:\n",
    "            G = G + (gamma**n) * Q[states[tau+n], actions[tau+n]]\n",
    "\n",
    "          Q[states[tau],actions[tau]] += alpha * (G - Q[states[tau], actions[tau]])\n",
    "          e = np.random.rand()\n",
    "          if e > epsilon:\n",
    "            policy = np.argmax(Q,axis=1) # Update Policy (eps-Greedy)\n",
    "          else:\n",
    "            policy = np.random.randint(n_actions, size=n_states)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "      \n",
    "      total_episode_length += t\n",
    "        \n",
    "    avg_ep_length = (total_episode_length/num_ep) \n",
    "    print(\"N =\",n,\" ||  α = {:.2f}\".format(alpha),\" || Avg. Episode_length =\",avg_ep_length)\n",
    "    return avg_ep_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m      6\u001b[0m   \u001b[39mfor\u001b[39;00m alpha \u001b[39min\u001b[39;00m alphas:\n\u001b[1;32m----> 7\u001b[0m     avg_ep_length \u001b[39m=\u001b[39m nstep_sarsa(env, n\u001b[39m=\u001b[39;49mn, alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[0;32m      8\u001b[0m     lst\u001b[39m.\u001b[39mappend((n,alpha,avg_ep_length))\n",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m, in \u001b[0;36mnstep_sarsa\u001b[1;34m(env, n, alpha, gamma, epsilon, num_ep)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" TODO: implement the n-step sarsa algorithm \"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m total_episode_length \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39;49m(num_ep)):      \n\u001b[0;32m      7\u001b[0m   state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      8\u001b[0m   obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[1;32mf:\\Fajri\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tqdm\\notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    237\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[1;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[0;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Fajri\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tqdm\\notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[0;32m    115\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "env=gym.make('FrozenLake-v1', map_name=\"8x8\")\n",
    "# TODO: run multiple times, evaluate the performance for different n and alpha\n",
    "alphas = np.linspace(0.1,1,10)\n",
    "lst = []\n",
    "for n in range(10):\n",
    "  for alpha in alphas:\n",
    "    avg_ep_length = nstep_sarsa(env, n=n, alpha=alpha)\n",
    "    lst.append((n,alpha,avg_ep_length))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "lst1 = [(alpha,ep) for _,alpha,ep in lst]\n",
    "for i in range(10):\n",
    "  L.append(lst1[i*10:(i+1)*10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,8))\n",
    "n=1\n",
    "for l in L:\n",
    "  x = []\n",
    "  y = []\n",
    "  for alpha,ep in l:\n",
    "    x.append(alpha)\n",
    "    y.append(ep)\n",
    "\n",
    "  plt.plot(x,y,'.-',label=\"n={}\".format(n))\n",
    "  n +=1\n",
    "\n",
    "plt.title(\"Performance evaluation of n-step Sarsa\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Average episode length\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "Q = np.random.rand(n_states,n_actions)\n",
    "\n",
    "Q[-1,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43761624, 0.91501471, 0.28239767, 0.83904564],\n",
       "       [0.35664074, 0.16325919, 0.77547215, 0.58251214],\n",
       "       [0.20226839, 0.14155432, 0.45851857, 0.41777359],\n",
       "       [0.9373139 , 0.78393293, 0.0941069 , 0.85912554],\n",
       "       [0.56786425, 0.04092345, 0.15243484, 0.4439364 ],\n",
       "       [0.0292349 , 0.93136014, 0.64013933, 0.96740915],\n",
       "       [0.01982391, 0.70192413, 0.31287939, 0.70682225],\n",
       "       [0.66911913, 0.60242446, 0.09147413, 0.79205722],\n",
       "       [0.5657016 , 0.2829793 , 0.67782511, 0.84047216],\n",
       "       [0.26709262, 0.00951066, 0.04972032, 0.60887756],\n",
       "       [0.77506222, 0.97768026, 0.41768402, 0.18616306],\n",
       "       [0.80064923, 0.8017395 , 0.23541502, 0.44839974],\n",
       "       [0.65408739, 0.02804732, 0.85202043, 0.15192572],\n",
       "       [0.14793886, 0.62959001, 0.63337127, 0.48622757],\n",
       "       [0.1079244 , 0.98983576, 0.69320117, 0.98970039],\n",
       "       [0.1729415 , 0.52857435, 0.02247676, 0.38941381],\n",
       "       [0.20604467, 0.6560551 , 0.08028435, 0.30933857],\n",
       "       [0.97374062, 0.74460109, 0.37382671, 0.1649109 ],\n",
       "       [0.50176141, 0.64032445, 0.87819485, 0.13011524],\n",
       "       [0.27093543, 0.22213893, 0.67953168, 0.34331571],\n",
       "       [0.97215528, 0.36476005, 0.92941545, 0.63311854],\n",
       "       [0.61600334, 0.75344455, 0.28265004, 0.24845588],\n",
       "       [0.71991141, 0.2228242 , 0.78531023, 0.09822552],\n",
       "       [0.89856986, 0.15814497, 0.61397243, 0.80720319],\n",
       "       [0.01702941, 0.56947136, 0.61398223, 0.09556364],\n",
       "       [0.5882689 , 0.36610442, 0.59197311, 0.02205113],\n",
       "       [0.02434241, 0.38730624, 0.09283789, 0.57914578],\n",
       "       [0.26736709, 0.17787376, 0.21478192, 0.30147659],\n",
       "       [0.21547921, 0.9122038 , 0.33378173, 0.45335051],\n",
       "       [0.18225791, 0.18482142, 0.94419927, 0.54568369],\n",
       "       [0.21107478, 0.13530702, 0.33736076, 0.4977956 ],\n",
       "       [0.60473201, 0.24081689, 0.52033117, 0.12245788],\n",
       "       [0.85674981, 0.6989431 , 0.69801602, 0.81303707],\n",
       "       [0.03612985, 0.27817649, 0.16047707, 0.75676277],\n",
       "       [0.89308776, 0.74810677, 0.28198936, 0.03896504],\n",
       "       [0.64861328, 0.47912226, 0.55586597, 0.09825377],\n",
       "       [0.0255268 , 0.73618182, 0.21119591, 0.73262593],\n",
       "       [0.55244752, 0.64708763, 0.83211683, 0.67717348],\n",
       "       [0.10892293, 0.39256831, 0.2785178 , 0.67526463],\n",
       "       [0.00544317, 0.78224932, 0.02776458, 0.58156157],\n",
       "       [0.35602013, 0.21721581, 0.37328263, 0.61212857],\n",
       "       [0.9875395 , 0.58843077, 0.01385249, 0.20640828],\n",
       "       [0.5178022 , 0.76995724, 0.92889981, 0.79159747],\n",
       "       [0.13555194, 0.5671666 , 0.30273344, 0.81226573],\n",
       "       [0.95771716, 0.70933914, 0.68220774, 0.87097036],\n",
       "       [0.38805274, 0.25172512, 0.28141568, 0.11645286],\n",
       "       [0.06516616, 0.45751619, 0.32769466, 0.19458608],\n",
       "       [0.50270177, 0.37456884, 0.29339778, 0.09940917],\n",
       "       [0.37939031, 0.60174769, 0.40903193, 0.67310366],\n",
       "       [0.60113457, 0.87745945, 0.1831482 , 0.9124662 ],\n",
       "       [0.56539459, 0.84643965, 0.49557329, 0.55633518],\n",
       "       [0.54341035, 0.65446172, 0.44484178, 0.43470868],\n",
       "       [0.36980408, 0.26526663, 0.45602822, 0.6282795 ],\n",
       "       [0.71424515, 0.61390256, 0.96040259, 0.07284572],\n",
       "       [0.14663977, 0.61601788, 0.49397985, 0.68419753],\n",
       "       [0.00885937, 0.41002952, 0.55747456, 0.78928578],\n",
       "       [0.35617129, 0.74879995, 0.75177002, 0.70150623],\n",
       "       [0.1869586 , 0.05718542, 0.86697298, 0.20038547],\n",
       "       [0.53669976, 0.4524111 , 0.9942372 , 0.71789064],\n",
       "       [0.02292981, 0.87903025, 0.39116035, 0.82935528],\n",
       "       [0.57012838, 0.6078207 , 0.75080176, 0.3536493 ],\n",
       "       [0.16166396, 0.9326726 , 0.05450551, 0.94298023],\n",
       "       [0.84252233, 0.97945618, 0.24403215, 0.49431315],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, numpy as np, matplotlib.pyplot as plt\n",
    "from neural_networks.policy_gradient_utilities import PolicyGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 5\n",
    "gamma = .99\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3\n",
    "n_episodes = 10000\n",
    "render = False\n",
    "goal = 190\n",
    "n_layers = 2\n",
    "n_classes = 2\n",
    "environment = gym.make('CartPole-v1')\n",
    "environment_dimension = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_reward(reward, gamma=gamma):\n",
    "    output = [reward[i] * gamma**i for i in range(0, len(reward))]\n",
    "    \n",
    "    return output[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, n_tests, render=render):\n",
    "   scores = []\n",
    "   for _ in range(n_tests):\n",
    "     environment.reset()\n",
    "     observation = environment.reset()\n",
    "     reward_sum = 0\n",
    "     while True:\n",
    "        if render:\n",
    "            environment.render()\n",
    "\n",
    "        state = np.reshape(observation, [1, environment_dimension])\n",
    "        predict = model.predict([state])[0]\n",
    "        action = np.argmax(predict)\n",
    "        observation, reward, done, _ = environment.step(action)\n",
    "        reward_sum += reward\n",
    "       \n",
    "        if done:\n",
    "           break\n",
    "        scores.append(reward_sum)\n",
    "        \n",
    "        environment.close()\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_pole_game(environment, policy_model, model_predictions):\n",
    "    loss = []\n",
    "    n_episode, reward_sum, score, episode_done = 0, 0, 0, False\n",
    "    n_actions = environment.action_space.n\n",
    "    observation = environment.reset()\n",
    "    states = np.empty(0).reshape(0, environment_dimension)\n",
    "    actions = np.empty(0).reshape(0, 1)\n",
    "    rewards = np.empty(0).reshape(0, 1)\n",
    "    discounted_rewards = np.empty(0).reshape(0, 1)\n",
    "\n",
    "    while n_episode < n_episodes:\n",
    "        state = np.array(observation)[None, :]  # Convert to numpy array and add an extra dimension\n",
    "        prediction = model_predictions.predict(state)[0]\n",
    "        action = np.random.choice(range(environment.action_space.n), p=prediction)\n",
    "        states = np.vstack([states, state])\n",
    "        actions = np.vstack([actions, action])\n",
    "        observation, reward, episode_done, info = environment.step(action)\n",
    "        reward_sum += reward\n",
    "        rewards = np.vstack([rewards, reward])\n",
    "\n",
    "        if episode_done == True:\n",
    "            discounted_reward = calculate_discounted_reward(rewards)\n",
    "            discounted_rewards = np.vstack([discounted_rewards, discounted_reward])\n",
    "            rewards = np.empty(0).reshape(0, 1)\n",
    "\n",
    "        if (n_episode + 1) % batch_size == 0:\n",
    "            discounted_rewards -= discounted_rewards.mean()\n",
    "            discounted_rewards /= discounted_rewards.std()\n",
    "            discounted_rewards = discounted_rewards.squeeze()\n",
    "            actions = actions.squeeze().astype(int)\n",
    "            train_actions = np.zeros([len(actions), n_actions])\n",
    "            train_actions[np.arange(len(actions)), actions] = 1\n",
    "            error = policy_model.train_on_batch([states, discounted_rewards], train_actions)\n",
    "            loss.append(error)\n",
    "            states = np.empty(0).reshape(0, environment_dimension)\n",
    "            actions = np.empty(0).reshape(0, 1)\n",
    "            discounted_rewards = np.empty(0).reshape(0, 1)\n",
    "            score = score_model(model=model_predictions, n_tests=10)\n",
    "            print('\\nEpisode: %s \\nAverage Reward: %s \\nScore: %s \\nError: %s' %(n_episode+1, reward_sum/float(batch_size), score, np.mean(loss[-batch_size:])))\n",
    "\n",
    "        if score >= goal:\n",
    "            break\n",
    "\n",
    "        reward_sum = 0\n",
    "        n_episode += 1\n",
    "        observation = environment.reset()\n",
    "\n",
    "    plt.title('Policy Gradient Error plot over %s Episodes'%(n_episode+1))\n",
    "    plt.xlabel('N batches')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.plot(loss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 5)            20          ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 2)            10          ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m policy_model, model_predictions \u001b[39m=\u001b[39m mlp_model\u001b[39m.\u001b[39mcreate_policy_model(environment_dimension,)\n\u001b[0;32m     15\u001b[0m policy_model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m---> 17\u001b[0m cart_pole_game(\n\u001b[0;32m     18\u001b[0m     environment\u001b[39m=\u001b[39;49menvironment,\n\u001b[0;32m     19\u001b[0m     policy_model\u001b[39m=\u001b[39;49mpolicy_model,\n\u001b[0;32m     20\u001b[0m     model_predictions\u001b[39m=\u001b[39;49mmodel_predictions\n\u001b[0;32m     21\u001b[0m )\n",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m, in \u001b[0;36mcart_pole_game\u001b[1;34m(environment, policy_model, model_predictions)\u001b[0m\n\u001b[0;32m      9\u001b[0m discounted_rewards \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m n_episode \u001b[39m<\u001b[39m n_episodes:\n\u001b[1;32m---> 12\u001b[0m     state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(observation)[\u001b[39mNone\u001b[39;00m, :]  \u001b[39m# Convert to numpy array and add an extra dimension\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     prediction \u001b[39m=\u001b[39m model_predictions\u001b[39m.\u001b[39mpredict(state)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(environment\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mn), p\u001b[39m=\u001b[39mprediction)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mlp_model = PolicyGradient(\n",
    "        n_units=n_units,\n",
    "        n_layers=n_layers,\n",
    "        n_columns=environment_dimension,\n",
    "        n_outputs=n_classes,\n",
    "        learning_rate=learning_rate,\n",
    "        hidden_activation='selu',\n",
    "        output_activation='softmax',\n",
    "        loss_function='log_likelihood'\n",
    "    )\n",
    "    \n",
    "    policy_model, model_predictions = mlp_model.create_policy_model(environment_dimension,)\n",
    "    \n",
    "    policy_model.summary()\n",
    "    \n",
    "    cart_pole_game(\n",
    "        environment=environment,\n",
    "        policy_model=policy_model,\n",
    "        model_predictions=model_predictions\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Munti Carlo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 105\u001b[0m\n\u001b[0;32m    101\u001b[0m     plot_blackjack(value, axes[\u001b[39m0\u001b[39m], axes[\u001b[39m1\u001b[39m])\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[45], line 95\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m'\u001b[39m\u001b[39mBlackjack-v1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m episodes \u001b[39m=\u001b[39m \u001b[39m500000\u001b[39m\n\u001b[1;32m---> 95\u001b[0m value \u001b[39m=\u001b[39m first_visit_MC(env, episodes)\n\u001b[0;32m     97\u001b[0m _, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\n\u001b[0;32m     98\u001b[0m     \u001b[39m6\u001b[39m, \u001b[39m9\u001b[39m), subplot_kw\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mprojection\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m3d\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     99\u001b[0m axes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mset_title(\u001b[39m'\u001b[39m\u001b[39mNo Usable ace\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 46\u001b[0m, in \u001b[0;36mfirst_visit_MC\u001b[1;34m(env, num_episodes)\u001b[0m\n\u001b[0;32m     42\u001b[0m n \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_episodes)):\n\u001b[1;32m---> 46\u001b[0m     states, actions, rewards \u001b[39m=\u001b[39m run_episode(env)\n\u001b[0;32m     47\u001b[0m     returns \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     49\u001b[0m     \u001b[39m# For each step calculate returns as a sum of rewards\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 21\u001b[0m, in \u001b[0;36mrun_episode\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m     18\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m     20\u001b[0m     \u001b[39m#print(\"Observation:\", obs)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mif\u001b[39;00m obs[\u001b[39m0\u001b[39;49m] \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m:\n\u001b[0;32m     22\u001b[0m         \u001b[39m# print(\"Stick\")\u001b[39;00m\n\u001b[0;32m     23\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     24\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m         \u001b[39m# print(\"Hit\")\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "def run_episode(env):\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    state = env.reset()\n",
    "    obs = env.reset()\n",
    "    action = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        #print(\"Observation:\", obs)\n",
    "        if obs[0] >= 20:\n",
    "            # print(\"Stick\")\n",
    "            action = 0\n",
    "        else:\n",
    "            # print(\"Hit\")\n",
    "            action = 1\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        #print(\"Reward:\", reward)\n",
    "        # print(\"\")\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        state = obs\n",
    "    return states, actions, rewards\n",
    "\n",
    "\n",
    "def first_visit_MC(env, num_episodes):\n",
    "\n",
    "    # Value table for storing the values of each state\n",
    "    value_table = defaultdict(float)\n",
    "    n = defaultdict(int)\n",
    "\n",
    "    for i in tqdm(range(num_episodes)):\n",
    "\n",
    "        states, actions, rewards = run_episode(env)\n",
    "        returns = 0\n",
    "\n",
    "        # For each step calculate returns as a sum of rewards\n",
    "        for t in range(len(states) - 1, -1, -1):\n",
    "            S = states[t]\n",
    "            R = rewards[t]\n",
    "\n",
    "            returns += R\n",
    "\n",
    "            # Check if the episode is visited for the first time =>\n",
    "            # If Yes: Assign the value of the state as an average of returns\n",
    "\n",
    "            if S not in states[:t]:\n",
    "                n[S] += 1\n",
    "                value_table[S] += (returns - value_table[S]) / n[S]\n",
    "\n",
    "    return value_table\n",
    "\n",
    "\n",
    "def plot_blackjack(V, ax1, ax2):\n",
    "    player_sum = np.arange(12, 21 + 1)\n",
    "    dealer_show = np.arange(1, 10 + 1)\n",
    "    usable_ace = np.array([False, True])\n",
    "    state_values = np.zeros(\n",
    "        (len(player_sum), len(dealer_show), len(usable_ace)))\n",
    "\n",
    "    for i, player in enumerate(player_sum):\n",
    "        for j, dealer in enumerate(dealer_show):\n",
    "            for k, ace in enumerate(usable_ace):\n",
    "                state_values[i, j, k] = V[player, dealer, ace]\n",
    "\n",
    "    X, Y = np.meshgrid(player_sum, dealer_show)\n",
    "\n",
    "    ax1.plot_wireframe(X, Y, state_values[:, :, 0])\n",
    "    ax2.plot_wireframe(X, Y, state_values[:, :, 1])\n",
    "\n",
    "    for ax in ax1, ax2:\n",
    "        ax.set_zlim(-1, 1)\n",
    "        ax.set_ylabel('Player sum')\n",
    "        ax.set_xlabel('Dealer showing')\n",
    "        ax.set_zlabel('State Value')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # This example shows how to perform a single run with the policy that hits for player_sum >= 20\n",
    "    env = gym.make('Blackjack-v1')\n",
    "    episodes = 500000\n",
    "    value = first_visit_MC(env, episodes)\n",
    "\n",
    "    _, axes = plt.subplots(nrows=2, figsize=(\n",
    "        6, 9), subplot_kw={'projection': '3d'})\n",
    "    axes[0].set_title('No Usable ace')\n",
    "    axes[1].set_title('Usable ace')\n",
    "    plot_blackjack(value, axes[0], axes[1])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Armed Banditsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current episode: 0\n",
      "current episode: 100\n",
      "current episode: 200\n",
      "current episode: 300\n",
      "current episode: 400\n",
      "current episode: 500\n",
      "current episode: 600\n",
      "current episode: 700\n",
      "current episode: 800\n",
      "current episode: 900\n",
      "current episode: 1000\n",
      "current episode: 1100\n",
      "current episode: 1200\n",
      "current episode: 1300\n",
      "current episode: 1400\n",
      "current episode: 1500\n",
      "current episode: 1600\n",
      "current episode: 1700\n",
      "current episode: 1800\n",
      "current episode: 1900\n",
      "current episode: 2000\n",
      "current episode: 2100\n",
      "current episode: 2200\n",
      "current episode: 2300\n",
      "current episode: 2400\n",
      "current episode: 2500\n",
      "current episode: 2600\n",
      "current episode: 2700\n",
      "current episode: 2800\n",
      "current episode: 2900\n",
      "current episode: 3000\n",
      "current episode: 3100\n",
      "current episode: 3200\n",
      "current episode: 3300\n",
      "current episode: 3400\n",
      "current episode: 3500\n",
      "current episode: 3600\n",
      "current episode: 3700\n",
      "current episode: 3800\n",
      "current episode: 3900\n",
      "current episode: 4000\n",
      "current episode: 4100\n",
      "current episode: 4200\n",
      "current episode: 4300\n",
      "current episode: 4400\n",
      "current episode: 4500\n",
      "current episode: 4600\n",
      "current episode: 4700\n",
      "current episode: 4800\n",
      "current episode: 4900\n",
      "current episode: 5000\n",
      "current episode: 5100\n",
      "current episode: 5200\n",
      "current episode: 5300\n",
      "current episode: 5400\n",
      "current episode: 5500\n",
      "current episode: 5600\n",
      "current episode: 5700\n",
      "current episode: 5800\n",
      "current episode: 5900\n",
      "current episode: 6000\n",
      "current episode: 6100\n",
      "current episode: 6200\n",
      "current episode: 6300\n",
      "current episode: 6400\n",
      "current episode: 6500\n",
      "current episode: 6600\n",
      "current episode: 6700\n",
      "current episode: 6800\n",
      "current episode: 6900\n",
      "current episode: 7000\n",
      "current episode: 7100\n",
      "current episode: 7200\n",
      "current episode: 7300\n",
      "current episode: 7400\n",
      "current episode: 7500\n",
      "current episode: 7600\n",
      "current episode: 7700\n",
      "current episode: 7800\n",
      "current episode: 7900\n",
      "current episode: 8000\n",
      "current episode: 8100\n",
      "current episode: 8200\n",
      "current episode: 8300\n",
      "current episode: 8400\n",
      "current episode: 8500\n",
      "current episode: 8600\n",
      "current episode: 8700\n",
      "current episode: 8800\n",
      "current episode: 8900\n",
      "current episode: 9000\n",
      "current episode: 9100\n",
      "current episode: 9200\n",
      "current episode: 9300\n",
      "current episode: 9400\n",
      "current episode: 9500\n",
      "current episode: 9600\n",
      "current episode: 9700\n",
      "current episode: 9800\n",
      "current episode: 9900\n",
      "Total reward of greedy strategy averaged over 10000 episodes: 8102.101958000696\n",
      "Total reward of epsilon greedy strategy averaged over 10000 episodes: 8504.632791995455\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "class GaussianBandit:\n",
    "    def __init__(self):\n",
    "        self._arm_means = np.random.uniform(0., 1., 10)  # Sample some means\n",
    "        self.n_arms = len(self._arm_means)\n",
    "        self.rewards = []\n",
    "        self.total_played = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.rewards = []\n",
    "        self.total_played = 0\n",
    "\n",
    "    def play_arm(self, a):\n",
    "        # Use sampled mean and covariance of 1.\n",
    "        reward = np.random.normal(self._arm_means[a], 1.)\n",
    "        self.total_played += 1\n",
    "        self.rewards.append(reward)\n",
    "        return reward\n",
    "\n",
    "\n",
    "def greedy(bandit, timesteps):\n",
    "    rewards = np.zeros(bandit.n_arms)\n",
    "    n_plays = np.zeros(bandit.n_arms)\n",
    "    Q = np.zeros(bandit.n_arms)\n",
    "    possible_arms = range(bandit.n_arms)\n",
    "\n",
    "    # TODO: init variables (rewards, n_plays, Q) by playing each arm once\n",
    "    for i in range(bandit.n_arms):\n",
    "        reward = bandit.play_arm(i)\n",
    "        rewards[i] += reward\n",
    "        n_plays[i] += 1\n",
    "        Q[i] = rewards[i]/n_plays[i]\n",
    "\n",
    "    # Main loop\n",
    "    while bandit.total_played < timesteps:\n",
    "        # This example shows how to play a random arm:\n",
    "        '''\n",
    "        a = random.choice(possible_arms)\n",
    "        reward_for_a = bandit.play_arm(a)\n",
    "        '''\n",
    "        # TODO: instead do greedy action selection\n",
    "        a = np.argmax(Q)\n",
    "        reward = bandit.play_arm(a)\n",
    "\n",
    "        # TODO: update the variables (rewards, n_plays, Q) for the selected arm\n",
    "        rewards[a] += reward\n",
    "        n_plays[a] += 1\n",
    "        Q[a] = rewards[a]/n_plays[a]\n",
    "\n",
    "\n",
    "def epsilon_greedy(bandit, timesteps, eps):\n",
    "    # Inititialize\n",
    "    rewards = np.zeros(bandit.n_arms)\n",
    "    n_plays = np.zeros(bandit.n_arms)\n",
    "    Q = np.zeros(bandit.n_arms)\n",
    "    possible_arms = range(bandit.n_arms)\n",
    "\n",
    "    # TODO: init variables (rewards, n_plays, Q) by playing each arm once\n",
    "    for i in range(bandit.n_arms):\n",
    "        reward = bandit.play_arm(i)\n",
    "        rewards[i] += reward\n",
    "        n_plays[i] += 1\n",
    "        Q[i] = rewards[i]/n_plays[i]\n",
    "\n",
    "    # TODO: epsilon greedy action selection (you can copy your code for greedy as a starting point)\n",
    "\n",
    "    while bandit.total_played < timesteps:\n",
    "        x = np.random.uniform()  # Uniform random distribution between [0,1]\n",
    "\n",
    "        if x >= eps:  # Explore\n",
    "            a = random.choice(possible_arms)\n",
    "        else:         # Exploit\n",
    "            a = np.argmax(Q)\n",
    "\n",
    "        reward = bandit.play_arm(a)\n",
    "        rewards[a] += reward\n",
    "        n_plays[a] += 1\n",
    "        Q[a] = rewards[a]/n_plays[a]\n",
    "\n",
    "\n",
    "def main():\n",
    "    n_episodes = 10000  # TODO: set to 10000 to decrease noise in plot\n",
    "    n_timesteps = 10000\n",
    "\n",
    "    eps = 0.9\n",
    "    rewards_greedy = np.zeros(n_timesteps)\n",
    "    rewards_egreedy = np.zeros(n_timesteps)\n",
    "\n",
    "    for i in range(n_episodes):\n",
    "        if i % 100 == 0:\n",
    "            print(\"current episode: \" + str(i))\n",
    "\n",
    "        b = GaussianBandit()  # initializes a random bandit\n",
    "        greedy(b, n_timesteps)\n",
    "        rewards_greedy += b.rewards\n",
    "\n",
    "        b.reset()  # reset the bandit before running epsilon_greedy\n",
    "        epsilon_greedy(b, n_timesteps, eps)\n",
    "        rewards_egreedy += b.rewards\n",
    "\n",
    "    rewards_greedy /= n_episodes\n",
    "    rewards_egreedy /= n_episodes\n",
    "    plt.plot(rewards_greedy, label=\"greedy\")\n",
    "    print(\"Total reward of greedy strategy averaged over \" +\n",
    "          str(n_episodes) + \" episodes: \" + str(np.sum(rewards_greedy)))\n",
    "    plt.plot(rewards_egreedy, label=\"e-greedy\")\n",
    "    print(\"Total reward of epsilon greedy strategy averaged over \" +\n",
    "          str(n_episodes) + \" episodes: \" + str(np.sum(rewards_egreedy)))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.savefig('bandit_strategies.png')\n",
    "    plt.show()\n",
    "    print(\"Enter:\")\n",
    "    input()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
